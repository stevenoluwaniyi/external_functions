{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5601078",
   "metadata": {},
   "source": [
    "## How to call functions with chat models\n",
    "\n",
    "OpenAI has added a number of dazzling features in its AI push, one that sparkled for me was the ability to call external functions. I translate this as being able to integrate external APIs into openAI's fleet of APIs including the chat completions API (fact check) used by chatgpt, Open AIs flagship product. This integration invites a wide range of possibilties. In this article, I show one of those, very simple but useful, possibilities in my article below\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models. In this case the chat completions api will be calling the weather api as an external function.\n",
    "\n",
    "The external function in this case is a python function. The python function retrieves the current weather information for a specified location using the OpenWeather API. This function is then called in the openai function. \n",
    "\n",
    "This way you can ask chat completions to give you the temperature reading for any location like you would ask a local at said destination ;)\n",
    "\n",
    "This is a very simple use case but knowing that you can integrate the OpenAI API with external APIs will give you the capability to build tools that can provide significant value to you in your day to day. From conversationally scheduling important events on your calendar (Google API) to making a last minute reservation to your favorite restuarant without having to go through multiple clicks.\n",
    "\n",
    "Please sure your thoughts on how external functions can be integrated into OpenAI API!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c7f61",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e626b",
   "metadata": {},
   "source": [
    "## 1. OpenAI API key\n",
    "\n",
    "Create OpenAI API key - https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751bf6a",
   "metadata": {},
   "source": [
    "# 2. Openweather API key\n",
    "\n",
    "Create Openweather API key - https://openweathermap.org/appid#:~:text=Once%20you%20sign%20up%20using,additional%20API%20keys%20if%20needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b3742",
   "metadata": {},
   "source": [
    "# Running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8577022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/f1/d8/590a68d390501faf48f4e57b098076df02afd003ac880f50d3b0704f7773/openai-1.8.0-py3-none-any.whl.metadata\n",
      "  Using cached openai-1.8.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Obtaining dependency information for anyio<5,>=3.5.0 from https://files.pythonhosted.org/packages/bf/cd/d6d9bb1dadf73e7af02d18225cbd2c93f8552e13130484f1c8dcfece292b/anyio-4.2.0-py3-none-any.whl.metadata\n",
      "  Using cached anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/dd/b7/9aea7ee6c01fe3f3c03b8ca3c7797c866df5fecece9d6cb27caa138db2e2/pydantic-2.5.3-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Obtaining dependency information for tqdm>4 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Obtaining dependency information for typing-extensions<5,>=4.7 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Obtaining dependency information for idna>=2.8 from https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl.metadata\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai)\n",
      "  Obtaining dependency information for pydantic-core==2.14.6 from https://files.pythonhosted.org/packages/7d/77/cbfa02b5f46c5ec6be131d97ae93eef883e25d61b4f4d0a058c792b7e3a2/pydantic_core-2.14.6-cp311-cp311-macosx_10_7_x86_64.whl.metadata\n",
      "  Using cached pydantic_core-2.14.6-cp311-cp311-macosx_10_7_x86_64.whl.metadata (6.5 kB)\n",
      "Using cached openai-1.8.0-py3-none-any.whl (222 kB)\n",
      "Using cached anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Using cached pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "Using cached pydantic_core-2.14.6-cp311-cp311-macosx_10_7_x86_64.whl (1.9 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.2.0 certifi-2023.11.17 distro-1.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 idna-3.6 openai-1.8.0 pydantic-2.5.3 pydantic-core-2.14.6 sniffio-1.3.0 tqdm-4.66.1 typing-extensions-4.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f8dd1",
   "metadata": {},
   "source": [
    "### Import all the necessary modules needed. Most important are openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "863361c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ee11e",
   "metadata": {},
   "source": [
    "##  Set the API keys environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db4681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPEN_WEATHER_API_KEY\"] = \"2990a9d7193a24a50a6bea7390b29210\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b46bb",
   "metadata": {},
   "source": [
    "## Assign a variable to the weather API and Open AI keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19a001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_api_key=os.getenv(\"OPEN_WEATHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f5bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74efb8f0",
   "metadata": {},
   "source": [
    "## Assign the OpenAI object to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174a18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938518d",
   "metadata": {},
   "source": [
    "### Function to convert from Kelvin to Fahrenheit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c98721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelvin_to_fahrenheit(kelvin):\n",
    "    return (kelvin - 273.15) * 9/5 + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e27c1c",
   "metadata": {},
   "source": [
    "### Define the get weather function that utilizes the Open weather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a695cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location,api_key=weather_api_key):\n",
    "    \"\"\"\n",
    "    Get current weather information for a given location using OpenWeather API.\n",
    "\n",
    "    Parameters:\n",
    "    - api_key (str): Your OpenWeather API key\n",
    "    - location (str): The location for which you want to get the weather information\n",
    "\n",
    "    Returns:\n",
    "    - dict: Weather information in a dictionary format\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    \n",
    "    location=location.lower()\n",
    "    \n",
    "    params = {\n",
    "        'q': location,\n",
    "        'appid': api_key,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            weather_info = {\n",
    "                'temperature': kelvin_to_fahrenheit(data['main']['temp']),\n",
    "            }\n",
    "            return json.dumps(f\"temperature_in_{location}: {weather_info['temperature']}\")\n",
    "        else:\n",
    "            return {'error': f\"Error {response.status_code}: {data['message']}\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {'error': f\"An error occurred: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cdc44",
   "metadata": {},
   "source": [
    "## Define the get temperature location function that utilizes the OpenAI API and integrates the external weather function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aca5af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temperature_location(location):\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    weather_prompt=f\"What's the weather like in {location}? Can you only use the city name and specify temperature in Fahrenheit?\"\n",
    "    messages = [{\"role\": \"user\", \"content\": weather_prompt }]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": { #this is where the external function is specified\n",
    "                \"name\": \"get_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"api_key\": {\"type\": \"string\", \"description\": \"api keys\"},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_weather\": get_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\")\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34814e71",
   "metadata": {},
   "source": [
    "## Test out the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9c56c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The temperature in London is 41.5 degrees Fahrenheit.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_temperature_location(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac4ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
